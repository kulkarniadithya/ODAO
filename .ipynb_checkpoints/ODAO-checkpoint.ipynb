{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "from transformers import BertForQuestionAnswering, BertModel\n",
    "from transformers import BertTokenizer\n",
    "import tqdm\n",
    "tqdmn = tqdm.notebook.tqdm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from sklearn.cross_decomposition import CCA\n",
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../../original_data/semeval14/restaurant/\"\n",
    "with open(str(path) + \"semeval_14_restaurant_sentence_dictionary_train_pairs_pseudo.pickle\", \"rb\") as handle:\n",
    "    train14 = pickle.load(handle)\n",
    "\n",
    "path = \"../../original_data/semeval16/\"\n",
    "with open(str(path) + \"semeval_16_restaurant_sentence_dictionary_train_pairs_pseudo.pickle\", \"rb\") as handle:\n",
    "    train16 = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_start_end_index(input_ids, solution):\n",
    "    start_index = 0\n",
    "    end_index = 0\n",
    "    tokens = tokenizer.convert_ids_to_tokens(input_ids)\n",
    "    start_boolean = False\n",
    "    end_boolean = False\n",
    "    for i in range(0, len(tokens)):\n",
    "        if tokens[i] == solution[0]:\n",
    "            start_index = i\n",
    "            start_boolean = True\n",
    "            break\n",
    "    for i in range(0, len(tokens)):\n",
    "        if tokens[i] == solution[-1]:\n",
    "            end_index = i\n",
    "            end_boolean = True\n",
    "            break\n",
    "    if (start_boolean == True) and (end_boolean == True):\n",
    "        return start_index, end_index\n",
    "    elif (start_boolean == False) and (end_boolean == True):\n",
    "        for i in range(0, len(tokens)):\n",
    "            if tokens[i].replace('##', '') in solution[0]:\n",
    "                start_index = i\n",
    "                start_boolean = True\n",
    "                break\n",
    "        return start_index, end_index\n",
    "    elif (start_boolean == True) and (end_boolean == False):\n",
    "        for i in range(0, len(tokens)):\n",
    "            if tokens[i].replace('##', '') in solution[-1]:\n",
    "                end_index = i\n",
    "                end_boolean = True\n",
    "                break\n",
    "        return start_index, end_index\n",
    "    elif (start_boolean == False) and (end_boolean == False):\n",
    "        for i in range(0, len(tokens)):\n",
    "            if tokens[i].replace('##', '') in solution[0]:\n",
    "                start_index = i\n",
    "                start_boolean = True\n",
    "                break\n",
    "        for i in range(0, len(tokens)):\n",
    "            if tokens[i].replace('##', '') in solution[-1]:\n",
    "                end_index = i\n",
    "                end_boolean = True\n",
    "                break\n",
    "        return start_index, end_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class construct_dataset(Dataset):\n",
    "    def __init__(self, question, text, answer, question_opinion, text_opinion, answer_opinion):\n",
    "        self.question = question\n",
    "        self.text = text\n",
    "        self.answer = answer\n",
    "        self.question_opinion = question_opinion\n",
    "        self.text_opinion = text_opinion\n",
    "        self.answer_opinion = answer_opinion\n",
    "    def __len__(self):\n",
    "        return len(self.question)\n",
    "    def __getitem__(self, idx):\n",
    "        query = self.question[idx].lower()\n",
    "        sent = self.text[idx].lower()\n",
    "        input_ids = tokenizer.encode(query, sent)\n",
    "        sep_idx = input_ids.index(tokenizer.sep_token_id)\n",
    "        num_seg_a = sep_idx+1\n",
    "        num_seg_b = len(input_ids) - num_seg_a\n",
    "        segment_ids = [0]*num_seg_a + [1]*num_seg_b\n",
    "        \n",
    "        query_opinion = self.question_opinion[idx].lower()\n",
    "        sent_opinion = self.text_opinion[idx].lower()\n",
    "        input_ids_opinion = tokenizer.encode(query_opinion, sent_opinion)\n",
    "        sep_idx_opinion = input_ids_opinion.index(tokenizer.sep_token_id)\n",
    "        num_seg_a_opinion = sep_idx_opinion+1\n",
    "        num_seg_b_opinion = len(input_ids_opinion) - num_seg_a_opinion\n",
    "        segment_ids_opinion = [0]*num_seg_a_opinion + [1]*num_seg_b_opinion\n",
    "        \n",
    "        term_input_ids = tokenizer.encode(sent)\n",
    "        term_sep_idx = term_input_ids.index(tokenizer.sep_token_id)\n",
    "        term_num_seg_a = term_sep_idx+1\n",
    "        term_num_seg_b = len(term_input_ids) - term_num_seg_a\n",
    "        term_segment_ids = [0]*term_num_seg_a + [1]*term_num_seg_b\n",
    "        \n",
    "        opinion_input_ids = tokenizer.encode(sent_opinion)\n",
    "        opinion_sep_idx = opinion_input_ids.index(tokenizer.sep_token_id)\n",
    "        opinion_num_seg_a = opinion_sep_idx+1\n",
    "        opinion_num_seg_b = len(opinion_input_ids) - opinion_num_seg_a\n",
    "        opinion_segment_ids = [0]*opinion_num_seg_a + [1]*opinion_num_seg_b\n",
    "\n",
    "        if self.answer[idx] not in ['[CLS]']:\n",
    "            solution = self.answer[idx].lower().split(\" \")\n",
    "        else:\n",
    "            solution = self.answer[idx].split(\" \")\n",
    "        \n",
    "        if self.answer_opinion[idx] not in ['[CLS]']:\n",
    "            solution_opinion = self.answer_opinion[idx].lower().split(\" \")\n",
    "        else:\n",
    "            solution_opinion = self.answer_opinion[idx].split(\" \")\n",
    "        \n",
    "        tokens_list = tokenizer.convert_ids_to_tokens(input_ids)\n",
    "        start_index, end_index = get_start_end_index(input_ids, solution)\n",
    "        term_start_index, term_end_index = get_start_end_index(term_input_ids, solution)\n",
    "        \n",
    "        start_index_opinion, end_index_opinion = get_start_end_index(input_ids_opinion, solution_opinion)\n",
    "        opinion_start_index, opinion_end_index = get_start_end_index(opinion_input_ids, solution_opinion)\n",
    "        \n",
    "        sample = {\"input_ids\": torch.tensor(input_ids), \"segment_ids\": torch.tensor(segment_ids), \"start_index\": torch.tensor(start_index), \"end_index\": torch.tensor(end_index),\n",
    "                 \"term_input_ids\": torch.tensor(term_input_ids), \"term_segment_ids\": torch.tensor(term_segment_ids), \"term_start_index\": torch.tensor(term_start_index),\n",
    "                  \"term_end_index\": torch.tensor(term_end_index),\n",
    "                 \"input_ids_opinion\": torch.tensor(input_ids_opinion), \"segment_ids_opinion\": torch.tensor(segment_ids_opinion), \"start_index_opinion\": torch.tensor(start_index_opinion), \"end_index_opinion\": torch.tensor(end_index_opinion),\n",
    "                 \"opinion_input_ids\": torch.tensor(opinion_input_ids), \"opinion_segment_ids\": torch.tensor(opinion_segment_ids), \"opinion_start_index\": torch.tensor(opinion_start_index),\n",
    "                  \"opinion_end_index\": torch.tensor(opinion_end_index)}\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dictionary = {}\n",
    "counter = 0\n",
    "for i in range(0, len(train14)):\n",
    "    train_dictionary[counter] = train14[i]\n",
    "    counter = counter + 1\n",
    "\n",
    "for i in range(0, len(train15)):\n",
    "    train_dictionary[counter] = train15[i]\n",
    "    counter = counter + 1\n",
    "\n",
    "for i in range(0, len(train16)):\n",
    "    train_dictionary[counter] = train16[i]\n",
    "    counter = counter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = []\n",
    "question = []\n",
    "answer = []\n",
    "for j in range(0, len(train_dictionary)):\n",
    "    sentence.append(train_dictionary[j]['sentence'])\n",
    "    question.append(train_dictionary[j]['opinion'])\n",
    "    answer.append(train_dictionary[j]['term'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_opinion = []\n",
    "question_opinion = []\n",
    "answer_opinion = []\n",
    "for j in range(0, len(train_dictionary)):\n",
    "    sentence_opinion.append(train_dictionary[j]['sentence'])\n",
    "    question_opinion.append(train_dictionary[j]['term'])\n",
    "    answer_opinion.append(train_dictionary[j]['opinion'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_version = 'bert-base-uncased'\n",
    "tokenizer = BertTokenizer.from_pretrained(bert_version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwolayerQA(nn.Module):\n",
    "\n",
    "    def __init__(self, device):\n",
    "\n",
    "        super(TwolayerQA, self).__init__()\n",
    "\n",
    "        self.bert_osae = BertModel.from_pretrained('bert-base-uncased')\n",
    "        self.bert_term = BertModel.from_pretrained('bert-base-uncased')\n",
    "        self.bert_asoe = BertModel.from_pretrained('bert-base-uncased')\n",
    "        self.bert_opinion = BertModel.from_pretrained('bert-base-uncased')\n",
    "        self.config = self.bert_osae.config\n",
    "        #print(self.config)\n",
    "        self.qa_outputs_osae = nn.Linear(self.config.hidden_size, 2)\n",
    "        self.qa_outputs_term = nn.Linear(self.config.hidden_size, 2)\n",
    "        self.qa_outputs_asoe = nn.Linear(self.config.hidden_size, 2)\n",
    "        self.qa_outputs_opinion = nn.Linear(self.config.hidden_size, 2)\n",
    "        #self.cca_loss_fn = cca_loss(outdim_size=self.config.hidden_size, use_all_singular_values=True, device=device)\n",
    "\n",
    "    def forward(self, input_ids, token_type_ids=None,term_token_type_ids=None, attention_mask=None, start_positions=None, end_positions=None, term_input_ids=None, term_attention_mask=None, term_start_positions=None, term_end_positions=None, input_ids_opinion=None, segment_ids_opinion=None, start_index_opinion=None,  end_index_opinion=None, opinion_input_ids=None, opinion_segment_ids=None, opinion_start_index=None, opinion_end_index=None):\n",
    "\n",
    "        output_osae = self.bert_osae(input_ids, token_type_ids, attention_mask)\n",
    "        term_output = self.bert_term(term_input_ids, term_token_type_ids, term_attention_mask)\n",
    "        \n",
    "        output_asoe = self.bert_asoe(input_ids_opinion, segment_ids_opinion, attention_mask)\n",
    "        opinion_output = self.bert_opinion(opinion_input_ids, opinion_segment_ids, term_attention_mask)\n",
    "        \n",
    "        logits = self.qa_outputs_osae(output_osae[0])\n",
    "        term_logits = self.qa_outputs_term(term_output[0])\n",
    "        start_logits, end_logits = logits.split(1, dim=-1)\n",
    "        start_logits = start_logits.squeeze(-1)\n",
    "        end_logits = end_logits.squeeze(-1)\n",
    "        \n",
    "        term_start_logits, term_end_logits = term_logits.split(1, dim=-1)\n",
    "        term_start_logits = term_start_logits.squeeze(-1)\n",
    "        term_end_logits = term_end_logits.squeeze(-1)\n",
    "        \n",
    "        \n",
    "        logits_opinion = self.qa_outputs_asoe(output_asoe[0])\n",
    "        opinion_logits = self.qa_outputs_opinion(opinion_output[0])\n",
    "        start_logits_opinion, end_logits_opinion = logits_opinion.split(1, dim=-1)\n",
    "        start_logits_opinion = start_logits_opinion.squeeze(-1)\n",
    "        end_logits_opinion = end_logits_opinion.squeeze(-1)\n",
    "        \n",
    "        opinion_start_logits, opinion_end_logits = opinion_logits.split(1, dim=-1)\n",
    "        opinion_start_logits = opinion_start_logits.squeeze(-1)\n",
    "        opinion_end_logits = opinion_end_logits.squeeze(-1)\n",
    "\n",
    "        if start_positions is not None and end_positions is not None and term_start_positions is not None and term_end_positions is not None:\n",
    "            if len(start_positions.size()) > 1:\n",
    "                start_positions = start_positions.squeeze(-1)\n",
    "            if len(end_positions.size()) > 1:\n",
    "                end_positions = end_positions.squeeze(-1)\n",
    "            \n",
    "            if len(term_start_positions.size()) > 1:\n",
    "                term_start_positions = term_start_positions.squeeze(-1)\n",
    "            if len(term_end_positions.size()) > 1:\n",
    "                term_end_positions = term_end_positions.squeeze(-1)\n",
    "                \n",
    "            if len(start_index_opinion.size()) > 1:\n",
    "                start_index_opinion = start_index_opinion.squeeze(-1)\n",
    "            if len(end_index_opinion.size()) > 1:\n",
    "                end_index_opinion = end_index_opinion.squeeze(-1)\n",
    "            \n",
    "            if len(opinion_start_index.size()) > 1:\n",
    "                opinion_start_index = opinion_start_index.squeeze(-1)\n",
    "            if len(opinion_end_index.size()) > 1:\n",
    "                opinion_end_index = opinion_end_index.squeeze(-1)\n",
    "            \n",
    "            loss_fct = CrossEntropyLoss()\n",
    "            start_loss = loss_fct(start_logits, start_positions)\n",
    "            end_loss = loss_fct(end_logits, end_positions)\n",
    "            total_loss = (start_loss + end_loss) / 2\n",
    "            \n",
    "            term_loss_fct = CrossEntropyLoss()\n",
    "            term_start_loss = term_loss_fct(term_start_logits, term_start_positions)\n",
    "            term_end_loss = term_loss_fct(term_end_logits, term_end_positions)\n",
    "            term_total_loss = (term_start_loss + term_end_loss) / 2\n",
    "            \n",
    "\n",
    "            start_loss_opinion = loss_fct(start_logits_opinion, start_index_opinion)\n",
    "            end_loss_opinion = loss_fct(end_logits_opinion, end_index_opinion)\n",
    "            total_loss_opinion = (start_loss_opinion + end_loss_opinion) / 2\n",
    "            \n",
    "            \n",
    "            opinion_start_loss = term_loss_fct(opinion_start_logits, opinion_start_index)\n",
    "            opinion_end_loss = term_loss_fct(opinion_end_logits, opinion_end_index)\n",
    "            opinion_total_loss = (opinion_start_loss + opinion_end_loss) / 2\n",
    "            \n",
    "            return total_loss, term_total_loss, total_loss_opinion, opinion_total_loss, output_osae, term_output, output_asoe, opinion_output\n",
    "        else:\n",
    "            return start_logits, end_logits, term_start_logits, term_end_logits, start_logits_opinion, end_logits_opinion, opinion_start_logits, opinion_end_logits, output_osae, term_output, output_asoe, opinion_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = construct_dataset(question, sentence, answer, question_opinion, sentence_opinion, answer_opinion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.AdamW(params=model.parameters(), lr=1e-5)\n",
    "n_epochs = 18\n",
    "train_data = torch.utils.data.DataLoader(train_dataset, batch_size=1)\n",
    "previous_correlation = 0\n",
    "diff = 0\n",
    "correlation_result = []\n",
    "for epochs in range(n_epochs):\n",
    "    train_loss = []\n",
    "    current_loss = 0\n",
    "    for i, batch in enumerate(tqdmn(train_data)):\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        segment_ids = batch['segment_ids'].to(device)\n",
    "        start_index = batch['start_index'].to(device)\n",
    "        end_index = batch['end_index'].to(device)\n",
    "        term_input_ids = batch['term_input_ids'].to(device)\n",
    "        term_segment_ids = batch['term_segment_ids'].to(device)\n",
    "        term_start_index = batch['term_start_index'].to(device)\n",
    "        term_end_index = batch['term_end_index'].to(device)\n",
    "        \n",
    "        input_ids_opinion = batch['input_ids_opinion'].to(device)\n",
    "        segment_ids_opinion = batch['segment_ids_opinion'].to(device)\n",
    "        start_index_opinion = batch['start_index_opinion'].to(device)\n",
    "        end_index_opinion = batch['end_index_opinion'].to(device)\n",
    "        opinion_input_ids = batch['opinion_input_ids'].to(device)\n",
    "        opinion_segment_ids = batch['opinion_segment_ids'].to(device)\n",
    "        opinion_start_index = batch['opinion_start_index'].to(device)\n",
    "        opinion_end_index = batch['opinion_end_index'].to(device)\n",
    "        \n",
    "        total_loss, term_total_loss, total_loss_opinion, opinion_total_loss, output_osae, term_output, output_asoe, opinion_output = model(input_ids=input_ids, token_type_ids=segment_ids, start_positions=start_index, end_positions=end_index, term_input_ids=term_input_ids, term_token_type_ids=term_segment_ids, term_start_positions=term_start_index, term_end_positions=term_end_index,input_ids_opinion=input_ids_opinion, segment_ids_opinion=segment_ids_opinion, start_index_opinion=start_index_opinion,  end_index_opinion=end_index_opinion, opinion_input_ids=opinion_input_ids, opinion_segment_ids=opinion_segment_ids, opinion_start_index=opinion_start_index, opinion_end_index=opinion_end_index)\n",
    "        X = term_output[0].squeeze().detach().cpu()\n",
    "        Y = output_osae[0].squeeze()[-len(X):].detach().cpu()\n",
    "        cca = CCA(n_components=4)\n",
    "        cca.fit(X, Y)\n",
    "        X_c, Y_c = cca.transform(X, Y)\n",
    "        result = np.corrcoef(X_c.T, Y_c.T)[0,1]\n",
    "        \n",
    "        X = opinion_output[0].squeeze().detach().cpu()\n",
    "        Y = output_asoe[0].squeeze()[-len(X):].detach().cpu()\n",
    "        cca = CCA(n_components=4)\n",
    "        cca.fit(X, Y)\n",
    "        X_c, Y_c = cca.transform(X, Y)\n",
    "        result_2 = np.corrcoef(X_c.T, Y_c.T)[0,1]\n",
    "        \n",
    "        correlation = result + result_2\n",
    "        \n",
    "        correlation_result.append(correlation)\n",
    "        loss = total_loss + term_total_loss + total_loss_opinion + opinion_total_loss\n",
    "        loss.backward()\n",
    "        current_loss += loss.item()\n",
    "        if i % 8 == 0 and i > 0:\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            train_loss.append(current_loss / 8)\n",
    "            current_loss = 0\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    torch.save(model, 'ODAO_CCA_correlation_epoch_' + str(epochs))\n",
    "    \n",
    "    print(\"Epoch: \" + str(epochs) + \" Correlation score: \" + str(np.mean(correlation_result)))\n",
    "    \n",
    "    print(\"Epoch: \" + str(epochs) + \" Average loss: \" + str(np.mean(train_loss)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
